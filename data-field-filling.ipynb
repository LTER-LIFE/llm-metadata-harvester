{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd0852d",
   "metadata": {},
   "source": [
    "# LLM-for-Metadata-Harvesting\n",
    "\n",
    "This notebook demonstrates the use of Large Language Models (LLMs) for automated metadata extraction from web-based dataset portals.  \n",
    "It showcases an experiment on the [Actual probability distribution for Quercus robur (2000â€“2020)](https://stac.ecodatacube.eu/veg_quercus.robur_anv.eml/collection.json?.language=en) dataset, using a combination of web scraping and LLM-based entity extraction to populate metadata fields according to the Croissant data standard.\n",
    "\n",
    "Key features:\n",
    "- Web scraping utilities for extracting full page text from dataset portals\n",
    "- Environment configuration for flexible API and model usage\n",
    "- LLM client support for OpenAI and Gemini models (with extensibility for custom clients)\n",
    "- Automated extraction of core metadata fields such as description, license, creator, keywords, and more\n",
    "\n",
    "The results of the experiment are presented at the end of the notebook.  \n",
    "Some code cells are included for future development and may not be directly relevant to this specific experiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0968a41",
   "metadata": {},
   "source": [
    "# Scrap from the web portal of the dataset\n",
    "\n",
    "You can use own-defined function to get the data from website, or use the pre-defined function in webutils.\n",
    "\n",
    "Mind that you should check the `robots.txt` first to make sure if it is legal or allowed to scrap from this website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35ccd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EcoDataCub\n"
     ]
    }
   ],
   "source": [
    "from llm_metadata_harvester.webutils import extract_full_page_text\n",
    "import nest_asyncio\n",
    "\n",
    "url = \"https://stac.ecodatacube.eu/veg_quercus.robur_anv.eml/collection.json?.language=en\"\n",
    "\n",
    "# Apply nest_asyncio to allow asyncio.run() in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run the async function\n",
    "full_text = await extract_full_page_text(url)\n",
    "\n",
    "# Optionally display or save it\n",
    "print(full_text[:10])  # Print the first 100 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48557b4",
   "metadata": {},
   "source": [
    "Alternatively, you can download the HTML of the webpage and read it as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf11b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./webpages/Actual probability distribution for Quercus robur (2000â€“2020).html\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    full_text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177743a",
   "metadata": {},
   "source": [
    "## ðŸ”§ Environment Configuration\n",
    "\n",
    "To configure your API keys or other environment variables, you can use a `.env` file or set them directly in your shell.\n",
    "\n",
    "### ðŸ“„ Using a `.env` File\n",
    "\n",
    "Place the `.env` file in **one** of the following locations:\n",
    "\n",
    "- The **root directory** of your project  \n",
    "- The **same directory** as the script you're running  \n",
    "- Or any directory, **as long as it's the current working directory**\n",
    "\n",
    "> â„¹ï¸ The `load_dotenv()` function automatically looks for a `.env` file in the current working directory by default.\n",
    "\n",
    "#### ðŸ’¡ Example `.env` File\n",
    "```env\n",
    "OPENAI_API_KEY=your_api_key_here\n",
    "ANOTHER_SECRET=value_here\n",
    "```\n",
    "\n",
    "### Using global environment variable\n",
    "\n",
    "Alternatively, you can set environment variables directly in your shell:\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=your_api_key_here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450e1c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from llm_metadata_harvester.harvester_operations import extract_entities\n",
    "from llm_metadata_harvester.llm_client import LLMClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# can put your .env file in the root of the project\n",
    "# or in the same directory as this script\n",
    "# or set the environment variables directly in your shell\n",
    "# load_dotenv() will look for a .env file in the current directory\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b08d2",
   "metadata": {},
   "source": [
    "## Metadata Fields\n",
    "\n",
    "The metadata fields defined below follow the **Croissant data standard**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667cec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metadata fields and their descriptions\n",
    "# These fields are from croissant data standard\n",
    "meta_field_dict = {\n",
    "    \"description\": \"Description of the dataset.\",\n",
    "    \"license\": \"The license of the dataset. Croissant recommends using the URL of a known license, e.g., one of the licenses listed at https://spdx.org/licenses/.\",\n",
    "    \"name\": \"The name of the dataset.\",\n",
    "    \"creator\": \"The creator(s) of the dataset.\",\n",
    "    \"datePublished\": \"The date the dataset was published.\",\n",
    "    \"keywords\": \"A set of keywords associated with the dataset, either as free text, or a DefinedTerm with a formal definition.\",\n",
    "    \"publisher\": \"The publisher of the dataset, which may be distinct from its creator.\",\n",
    "    \"sameAs\": \"The URL of another Web resource that represents the same dataset as this one.\",\n",
    "    \"dateModified\": \"The date the dataset was last modified.\",\n",
    "    \"inLanguage\": \"The language(s) of the content of the dataset.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af489ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Metadata date': 'N/A;',\n",
       " 'Metadata language': 'English;',\n",
       " 'Responsible organization metadata': 'Opengeohub;',\n",
       " 'Landing page': 'https://doi.org/10.5281/zenodo.5887415;',\n",
       " 'Title': 'Actual probability distribution for Quercus robur (2000â€“2020);',\n",
       " 'Description': 'Actual Natural Vegetation (ANV): probability of occurrence for the Pedunculate oak in its realized environment for the period 2000 - 2033;',\n",
       " 'Unique Identifier': 'https://doi.org/10.5281/zenodo.5887415;',\n",
       " 'Resource type': 'Species distribution model;',\n",
       " 'Keywords': 'species distribution model, tree species, landsat;',\n",
       " 'Data creator': 'Carmelo Bonannella;',\n",
       " 'Data contact point': 'carmelo.bonannella@opengeohub.org;',\n",
       " 'Data publisher': 'Opengeohub;',\n",
       " 'Spatial coverage': 'N/A;',\n",
       " 'Spatial resolution': 'N/A;',\n",
       " 'Spatial reference system': 'N/A;',\n",
       " 'Temporal coverage': '2000-01-01 00:00:00 UTC â€“ 2020-12-31 00:00:00 UTC;',\n",
       " 'Temporal resolution': 'Multi-year intervals;',\n",
       " 'License': 'CC-BY-SA-4.0;',\n",
       " 'Access rights': 'Public with attribution;',\n",
       " 'Distribution access URL': 'https://doi.org/10.5281/zenodo.5887415;',\n",
       " 'Distribution format': 'COG;',\n",
       " 'Distribution byte size': 'N/A;'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_metadata_harvester.harvester_operations import metadata_harvest\n",
    "from llm_metadata_harvester.standards import LTER_LIFE_STANDARD\n",
    "\n",
    "extracted_metadata = await metadata_harvest(\n",
    "    model_name=\"gemini-2.5-flash-preview-05-20\",\n",
    "    url = \"https://stac.ecodatacube.eu/veg_quercus.robur_anv.eml/collection.json?.language=en\",\n",
    "    metadata_standard=LTER_LIFE_STANDARD)\n",
    "\n",
    "extracted_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef2b60",
   "metadata": {},
   "source": [
    "## LLM Client Support\n",
    "\n",
    "The `llm client` currently supports **OpenAI** and **Gemini** models.\n",
    "\n",
    "To use other models, you can define your own LLM client class.  \n",
    "Your custom class should implement a `chat` method that returns a string as the LLM response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b7232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLMClient(model_name=\"gemini-2.5-flash-preview-05-20\", temperature=0.0)\n",
    "\n",
    "clean_nodes = extract_entities(\n",
    "    text=full_text,\n",
    "    meta_field_dict=meta_field_dict,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85390a84",
   "metadata": {},
   "source": [
    "The output of `extract_entities` looks like a list of lists of dictionaries, where each dictionary is structured like this:\n",
    "\n",
    "```python\n",
    "'license': [{'entity_name': 'license',\n",
    "             'entity_value': 'CC-BY-SA-4.0',\n",
    "             'source_id': 'chunk_0',\n",
    "             'file_path': 'unknown_source'}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b8d6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match: {'title': True}\n",
      "Fuzzy match: {'title': True}\n",
      "No match: {'title': False}\n",
      "Multiple values: {'title': True, 'author': True}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "extracted_metadata is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m metadata = {}\n\u001b[32m     23\u001b[39m raw_text = \u001b[33m\"\u001b[39m\u001b[33mSome text.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEmpty metadata:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mcheck_exist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_text\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Should print False\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/final_submission_llm_metadata_harvester/src/llm_metadata_harvester/checks.py:13\u001b[39m, in \u001b[36mcheck_exist\u001b[39m\u001b[34m(extracted_metadata, raw_input, threshold)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check if metadata value exist in raw input using fuzzy matching.\u001b[39;00m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[33;03mFor each value in ``extracted_metadata`` this does a fuzzy substring match\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03magainst ``raw_input``. Returns a tuple of booleans for each metadata value.\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m extracted_metadata:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mextracted_metadata is empty\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m hay = (raw_input \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).lower()\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hay:\n",
      "\u001b[31mValueError\u001b[39m: extracted_metadata is empty"
     ]
    }
   ],
   "source": [
    "from llm_metadata_harvester.checks import *\n",
    "metadata = {\"title\": \"Quercus robur\"}\n",
    "raw_text = \"Actual probability distribution for Quercus robur (2000â€“2020).\"\n",
    "print(\"Exact match:\", check_exist(metadata, raw_text))  # Should print True\n",
    "\n",
    "# Example 2: Fuzzy match\n",
    "metadata = {\"title\": \"Quercus roburrr\"}\n",
    "raw_text = \"Actual probability distribution for Quercus roburr (2000â€“2020).\"\n",
    "print(\"Fuzzy match:\", check_exist(metadata, raw_text, threshold=0.8))  # Should print True\n",
    "\n",
    "# Example 3: No match\n",
    "metadata = {\"title\": \"Pinus sylvestris\"}\n",
    "raw_text = \"Actual probability distribution for Quercus robur (2000â€“2020).\"\n",
    "print(\"No match:\", check_exist(metadata, raw_text))  # Should print False\n",
    "\n",
    "# Example 4: Multiple metadata values\n",
    "metadata = {\"title\": \"Quercus robur\", \"author\": \"John Smith\"}\n",
    "raw_text = \"John Smith studied the distribution of Quercus robur.\"\n",
    "print(\"Multiple values:\", check_exist(metadata, raw_text))  # Should print True\n",
    "\n",
    "# Example 5: Empty metadata\n",
    "metadata = {}\n",
    "raw_text = \"Some text.\"\n",
    "print(\"Empty metadata:\", check_exist(metadata, raw_text))  # Should print False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889d4879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact repeat: {'title': True}\n",
      "Fuzzy repeat: {'title': True}\n",
      "No repeat: {'title': False}\n",
      "Multiple keys: {'title': True, 'author': False}\n",
      "Empty value in metadata: {'title': False, 'author': False}\n"
     ]
    }
   ],
   "source": [
    "from llm_metadata_harvester.checks import *\n",
    "\n",
    "extracted_metadata = {\"title\": \"Quercus robur\"}\n",
    "metadata_definition = {\"title\": \"Quercus robur\"}\n",
    "print(\"Exact repeat:\", check_repeat_prompt(extracted_metadata, metadata_definition))  # (True,)\n",
    "\n",
    "# Example 2: Fuzzy repeat\n",
    "extracted_metadata = {\"title\": \"Quercus roburr\"}\n",
    "metadata_definition = {\"title\": \"Quercus robur\"}\n",
    "print(\"Fuzzy repeat:\", check_repeat_prompt(extracted_metadata, metadata_definition, threshold=0.8))  # (True,)\n",
    "\n",
    "# Example 3: No repeat\n",
    "extracted_metadata = {\"title\": \"Pinus sylvestris\"}\n",
    "metadata_definition = {\"title\": \"Quercus robur\"}\n",
    "print(\"No repeat:\", check_repeat_prompt(extracted_metadata, metadata_definition))  # (False,)\n",
    "\n",
    "# Example 4: Multiple keys\n",
    "extracted_metadata = {\"title\": \"Quercus robur\", \"author\": \"John Smith\"}\n",
    "metadata_definition = {\"title\": \"Quercus robur\", \"author\": \"Jane Doe\"}\n",
    "print(\"Multiple keys:\", check_repeat_prompt(extracted_metadata, metadata_definition))  # (True, False)\n",
    "\n",
    "# Example 5: Empty value in metadata\n",
    "extracted_metadata = {\"title\": \"\", \"author\": None}\n",
    "metadata_definition = {\"title\": \"Quercus robur\", \"author\": \"Jane Doe\"}\n",
    "print(\"Empty value in metadata:\", check_repeat_prompt(extracted_metadata, metadata_definition))  # (False, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a799ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_metadata_harvester.harvester_operations import metadata_harvest\n",
    "from dotenv import load_dotenv\n",
    "from llm_metadata_harvester.standards import LTER_LIFE_STANDARD\n",
    "import nest_asyncio\n",
    "# Apply nest_asyncio to allow asyncio.run() in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()\n",
    "metadata = await metadata_harvest(\n",
    "    model_name=\"gemini-2.5-flash-preview-05-20\",\n",
    "    url=\"https://stac.ecodatacube.eu/veg_quercus.robur_anv.eml/collection.json?.language=en\",\n",
    "    meta_field_dict=meta_field_dict\n",
    ")\n",
    "# default lter-life, \n",
    "# string -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5215526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Actual Natural Vegetation (ANV) refers to the probability of occurrence for the Pedunculate oak in its realized environment for the period 2000-2033.;',\n",
       " 'license': 'CC-BY-SA-4.0;',\n",
       " 'name': 'Actual Probability Distribution for Quercus Robur;',\n",
       " 'creator': 'Carmelo Bonannella;',\n",
       " 'datePublished': '2000-01-01;',\n",
       " 'keywords': 'Species Distribution Model, Tree Species, Landsat;',\n",
       " 'publisher': 'OpenGeoHub;',\n",
       " 'sameAs': 'https://doi.org/10.5281/zenodo.5887415;',\n",
       " 'dateModified': '2020-12-31;',\n",
       " 'inLanguage': 'English;'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236b028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
