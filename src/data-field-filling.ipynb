{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd0852d",
   "metadata": {},
   "source": [
    "# LLM-for-Metadata-Harvesting\n",
    "\n",
    "This notebook contains the experimental results from [P6: Groot zeegras (2023)](https://datahuiswadden.openearth.nl/geonetwork/srv/api/records/TF1TbsTxTqykP5rv6MXJEg).  \n",
    "The results can be found under the last code block. Note that not all code is directly relevant to this experiment; some parts are retained for future development and elaboration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d59c2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip to main content\n",
      "\n",
      "developers.google.com uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic. Learn more.\n",
      "\n",
      "OK, got it\n",
      "Earth Engine Data Catalog\n",
      "/\n",
      "Sign in\n",
      "Home\n",
      "Categories\n",
      "All datasets\n",
      "All tags\n",
      "Landsat\n",
      "MODIS\n",
      "Sentinel\n",
      "Publisher\n",
      "Community\n",
      "API Docs\n",
      "HLSS30: HLS Sentinel-2 Multi-spectral Instrument Surface Reflectance Daily Global 30m\n",
      "bookmark_border\n",
      "Dataset Availability\n",
      "2015-11-28T00:00:00Z–2025-07-04T23:46:41Z\n",
      "Dataset Provider\n",
      "NASA LP DAAC\n",
      "Earth Engine Snippet\n",
      "ee.ImageCollection(\"NASA/HLS/HLSS30/v002\") open_in_new\n",
      "Tags\n",
      "landsat nasa satellite-imagery sentinel usgs\n",
      "Description\n",
      "Bands\n",
      "Image Properties\n",
      "Terms of Use\n",
      "Citations\n",
      "DOIs\n",
      "\n",
      "The Harmonized Landsat Sentinel-2 (HLS) project provides consistent surface reflectance data from the Operational Land Imager (OLI) aboard the joint NASA/USGS Landsat 8 satellite and the Multi-Spectral Instrument (MSI) aboard Europe's Copernicus Sentinel-2A satellites. The combined measurement enables global observations of the land every 2-3 days at 30-meter (m) spatial resolution. The HLS project uses a set of algorithms to obtain seamless products from OLI and MSI that include atmospheric correction, cloud and cloud-shadow masking, spatial co-registration and common gridding, illumination and view angle normalization, and spectral bandpass adjustment.\n",
      "\n",
      "The HLS project distributes data as two separate products: HLSL30 (Landsat 8/9) and HLSS30 (Sentinel-2 A/B). They both provide 30m Nadir Bidirectional Reflectance Distribution Function (BRDF), Adjusted Reflectance (NBAR).\n",
      "\n",
      "Documentation:\n",
      "\n",
      "User's Guide\n",
      "\n",
      "Algorithm Theoretical Basis Document (ATBD)\n",
      "\n",
      "General Documentation\n",
      "\n",
      "L30 catalog link: NASA/HLS/HLSL30/v002\n",
      "\n",
      "Note: The historical assets are currently being ingested and this process is expected to finish in 2025.\n",
      "Explore with Earth Engine\n",
      "Important: Earth Engine is a platform for petabyte-scale scientific analysis and visualization of geospatial datasets, both for public benefit and for business and government users. Earth Engine is free to use for research, education, and nonprofit use. To get started, please register for Earth Engine access.\n",
      "Code Editor (JavaScript)\n",
      "var collection = ee.ImageCollection(\"NASA/HLS/HLSS30/v002\")\n",
      "                    .filter(ee.Filter.date('2024-04-25', '2024-04-26'))\n",
      "                    .filter(ee.Filter.lt('CLOUD_COVERAGE', 30));\n",
      "var visParams = {\n",
      "  bands: ['B4', 'B3', 'B2'],\n",
      "  min:0.01,\n",
      "  max:0.18,\n",
      "};\n",
      "\n",
      "var visualizeImage = function(image) {\n",
      "  var imageRGB = image.visualize(visParams);\n",
      "  return imageRGB;\n",
      "};\n",
      "\n",
      "var rgbCollection = collection.map(visualizeImage);\n",
      "\n",
      "Map.setCenter(-109.53, 29.19, 12)\n",
      "Map.addLayer(rgbCollection, {}, 'HLS S30 RGB bands');\n",
      "Open in Code Editor\n",
      "GitHub\n",
      "Earth Engine on GitHub\n",
      "Medium\n",
      "Follow our blog on Medium\n",
      "GIS Stack Exchange\n",
      "Ask questions using the google-earth-engine tag\n",
      "Twitter\n",
      "Follow @googleearth on Twitter\n",
      "Videos\n",
      "Earth Engine on YouTube\n",
      "Connect\n",
      "Blog\n",
      "Instagram\n",
      "LinkedIn\n",
      "X (Twitter)\n",
      "YouTube\n",
      "Programs\n",
      "Google Developer Groups\n",
      "Google Developer Experts\n",
      "Accelerators\n",
      "Women Techmakers\n",
      "Google Cloud & NVIDIA\n",
      "Developer consoles\n",
      "Google API Console\n",
      "Google Cloud Platform Console\n",
      "Google Play Console\n",
      "Firebase Console\n",
      "Actions on Google Console\n",
      "Cast SDK Developer Console\n",
      "Chrome Web Store Dashboard\n",
      "Google Home Developer Console\n",
      "Android\n",
      "Chrome\n",
      "Firebase\n",
      "Google Cloud Platform\n",
      "Google AI\n",
      "All products\n",
      "Terms\n",
      "Privacy\n",
      "Sign up for the Google for Developers newsletter\n",
      "Subscribe\n",
      "Info\n",
      "Chat\n",
      "API\n"
     ]
    }
   ],
   "source": [
    "from cheatsheet import CHEATSHEETS\n",
    "from prompt import PROMPTS\n",
    "from webutils import readWebContent, downloadAndParseXML\n",
    "\n",
    "dataPortalURL = [\n",
    "    \"https://developers.google.com/earth-engine/datasets/catalog/NASA_HLS_HLSS30_v002\",\n",
    "    \"https://lpdaac.usgs.gov/products/mod09a1v061/\",\n",
    "    \"https://stac.ecodatacube.eu/veg_quercus.robur_anv.eml/collection.json?.language=en\",\n",
    "    \"https://stac.ecodatacube.eu/ndvi_glad.landsat.ard2.seasconv/collection.json?.language=en\",\n",
    "    \"https://zenodo.org/records/8319440\",\n",
    "    \"https://lifesciences.datastations.nl/dataset.xhtml?persistentId=doi:10.17026/dans-2bd-kskz\",\n",
    "    \"https://www.gbif.org/dataset/4fa7b334-ce0d-4e88-aaae-2e0c138d049e\",\n",
    "    \"https://www.gbif.org/dataset/74196cd9-7ebc-4b20-bc27-3c2d22e31ed7\",\n",
    "    \"https://www.gbif.org/dataset/f9ba3c2e-0636-4f66-a4b5-b8c138046e9e\",\n",
    "    \"https://www.gbif.org/dataset/bc0acb9a-131f-4085-93ae-a46e08564ac5\",\n",
    "    \"https://zenodo.org/records/11440456\",\n",
    "    \"https://stac.ecodatacube.eu/blue_glad.landsat.ard2.seasconv.m.yearly/collection.json\",\n",
    "    \"https://datahuiswadden.openearth.nl/geonetwork/srv/eng/catalog.search#/metadata/L-mHomzGRuKAHGMkUPjY9g\",\n",
    "    \"https://datahuiswadden.openearth.nl/geonetwork/srv/eng/catalog.search#/metadata/0fe7e64b-50b3-4cee-b64a-02659fc2b6c7\",\n",
    "    \"https://stac.ecodatacube.eu/green_glad.landsat.ard2.seasconv.m.yearly/collection.json\",\n",
    "    \"https://datahuiswadden.openearth.nl/geonetwork/srv/api/records/A0h06_NlSEuNlium5OO3FA\",\n",
    "]\n",
    "\n",
    "# Get the web content\n",
    "url = dataPortalURL[0]\n",
    "\n",
    "\n",
    "# soup = readWebContent(url)\n",
    "# if soup is None:\n",
    "#     raise ValueError(\"Failed to retrieve web content\")\n",
    "\n",
    "# # Extract text from the webpage - adjust the selector based on the webpage structure\n",
    "# # This is a basic example - you might need to modify based on the specific webpage\n",
    "# text = soup.get_text(separator='\\n', strip=True)\n",
    "\n",
    "# text_xml, _ = downloadAndParseXML(\"https://datahuiswadden.openearth.nl/geonetwork/srv/api/records/A0h06_NlSEuNlium5OO3FA/formatters/xml\")\n",
    "# text += \"\\n\" + text_xml\n",
    "# full_text = text\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from webutils import extract_full_page_text\n",
    "\n",
    "# Apply nest_asyncio to allow asyncio.run() in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Run the async function\n",
    "full_text = await extract_full_page_text(url)\n",
    "\n",
    "# Optionally display or save it\n",
    "print(full_text)  # Print the first 1000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91c5532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [00:39<09:49, 39.30s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from harvester_operations import extract_entities\n",
    "from llm_client import LLMClient\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "initial_url_map = {}\n",
    "clean_url_map = {}\n",
    "\n",
    "index = 0\n",
    "\n",
    "for url in tqdm(dataPortalURL):\n",
    "    index += 1\n",
    "    if index >1:\n",
    "        break\n",
    "    # Apply nest_asyncio to allow asyncio.run() in Jupyter\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    # Run the async function\n",
    "    if url.startswith(\"https://lpdaac.usgs.gov\"):\n",
    "        soup = readWebContent(url)\n",
    "        if soup is None:\n",
    "            raise ValueError(\"Failed to retrieve web content\")\n",
    "\n",
    "        # Extract text from the webpage - adjust the selector based on the webpage structure\n",
    "        # This is a basic example - you might need to modify based on the specific webpage\n",
    "        full_text = soup.get_text(separator='\\n', strip=True)\n",
    "    else:\n",
    "        full_text = await extract_full_page_text(url)\n",
    "\n",
    "    # Optionally display or save it\n",
    "    ###############################################################\n",
    "    special_interest = CHEATSHEETS.get(\"special_interests\", \"Focus on metadata fields and their relationships\")\n",
    "    entity_types = PROMPTS[\"DEFAULT_ENTITY_TYPES\"]\n",
    "    is_croissant=False\n",
    "    # special_interest = CHEATSHEETS.get(\"special_interests_croissant\")\n",
    "    # entity_types = PROMPTS[\"CROISSANT_ENTITY_TYPES\"]\n",
    "    # is_croissant=True\n",
    "\n",
    "    meta_field_dict = {\n",
    "        \"description\": \"Description of the dataset.\",\n",
    "        \"license\": \"The license of the dataset. Croissant recommends using the URL of a known license, e.g., one of the licenses listed at https://spdx.org/licenses/.\",\n",
    "        \"name\": \"The name of the dataset.\",\n",
    "        \"creator\": \"The creator(s) of the dataset.\",\n",
    "        \"datePublished\": \"The date the dataset was published.\",\n",
    "        \"keywords\": \"A set of keywords associated with the dataset, either as free text, or a DefinedTerm with a formal definition.\",\n",
    "        \"publisher\": \"The publisher of the dataset, which may be distinct from its creator.\",\n",
    "        \"sameAs\": \"The URL of another Web resource that represents the same dataset as this one.\",\n",
    "        \"dateModified\": \"The date the dataset was last modified.\",\n",
    "        \"inLanguage\": \"The language(s) of the content of the dataset.\"\n",
    "    }\n",
    "    ###############################################################\n",
    "\n",
    "    llm = LLMClient(model_name=\"gemini-2.5-flash-preview-05-20\", temperature=0.0)\n",
    "\n",
    "    initial_nodes, clean_nodes = extract_entities(\n",
    "        text=full_text,\n",
    "        meta_field_dict=meta_field_dict,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    initial_entity_type_map = {}\n",
    "\n",
    "    for entity_group in initial_nodes.values():\n",
    "        for item in entity_group:\n",
    "            entity_name = item.get('entity_name')\n",
    "            entity_type = item.get('entity_type')\n",
    "            entity_description = item.get('description')\n",
    "\n",
    "            # Initialize the list for this entity_type if not already present\n",
    "            if entity_name not in initial_entity_type_map:\n",
    "                initial_entity_type_map[entity_type] = []\n",
    "\n",
    "            # Append the (entity_name, description) pair\n",
    "            initial_entity_type_map[entity_type].append(entity_name + '; ' + entity_description)\n",
    "    initial_url_map[url] = initial_entity_type_map\n",
    "\n",
    "    # Create a dictionary to store entity_type: [(entity_name, description), ...]\n",
    "    clean_entity_type_map = {}\n",
    "\n",
    "    for entity_group in clean_nodes.values():\n",
    "        for item in entity_group:\n",
    "            entity_name = item.get('entity_name')\n",
    "            entity_value = item.get('entity_value')\n",
    "\n",
    "            # Initialize the list for this entity_type if not already present\n",
    "            if entity_name not in clean_entity_type_map:\n",
    "                clean_entity_type_map[entity_name] = []\n",
    "\n",
    "            # Append the (entity_name, description) pair\n",
    "            clean_entity_type_map[entity_name].append(entity_value)\n",
    "    clean_url_map[url] = clean_entity_type_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "329c84b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'description': [{'entity_name': 'description',\n",
       "               'entity_value': \"The HLSS30 product, part of the Harmonized Landsat Sentinel-2 (HLS) project, provides consistent surface reflectance data at 30-meter spatial resolution from the Multi-Spectral Instrument (MSI) aboard Europe's Copernicus Sentinel-2A satellites.\",\n",
       "               'source_id': 'chunk_0',\n",
       "               'file_path': 'unknown_source'}],\n",
       "             'license': [{'entity_name': 'license',\n",
       "               'entity_value': 'Earth Engine, which hosts HLSS30, is free to use for research, education, and nonprofit use.',\n",
       "               'source_id': 'chunk_0',\n",
       "               'file_path': 'unknown_source'}],\n",
       "             'name': [{'entity_name': 'name',\n",
       "               'entity_value': 'HLSS30: HLS Sentinel-2 Multi-spectral Instrument Surface Reflectance Daily Global 30m',\n",
       "               'source_id': 'chunk_0',\n",
       "               'file_path': 'unknown_source'}],\n",
       "             'creator': [{'entity_name': 'creator',\n",
       "               'entity_value': 'NASA LP DAAC',\n",
       "               'source_id': 'chunk_0',\n",
       "               'file_path': 'unknown_source'}],\n",
       "             'datePublished': [{'entity_name': 'datePublished',\n",
       "               'entity_value': '2015-11-28T00:00:00Z',\n",
       "               'source_id': 'chunk_0',\n",
       "               'file_path': 'unknown_source'}],\n",
       "             'keywords': [{'entity_name': 'keywords',\n",
       "               'entity_value': 'landsat, nasa, satellite-imagery, sentinel, usgs',\n",
       "               'source_id': 'chunk_0',\n",
       "               'file_path': 'unknown_source'}],\n",
       "             'publisher': [{'entity_name': 'publisher',\n",
       "               'entity_value': 'Earth Engine',\n",
       "               'source_id': 'chunk_0',\n",
       "               'file_path': 'unknown_source'}],\n",
       "             'sameAs': [{'entity_name': 'sameAs',\n",
       "               'entity_value': 'ee.ImageCollection(\"NASA/HLS/HLSS30/v002\")',\n",
       "               'source_id': 'chunk_0',\n",
       "               'file_path': 'unknown_source'}],\n",
       "             'dateModified': [{'entity_name': 'dateModified',\n",
       "               'entity_value': '2025-07-04T23:46:41Z',\n",
       "               'source_id': 'chunk_0',\n",
       "               'file_path': 'unknown_source'}],\n",
       "             'inLanguage': [{'entity_name': 'inLanguage',\n",
       "               'entity_value': 'English',\n",
       "               'source_id': 'chunk_0',\n",
       "               'file_path': 'unknown_source'}]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5af097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_str = now.strftime(\"%Y-%m-%d\") \n",
    "prefix = \"cedar_openai_\"\n",
    "\n",
    "output_file_path = \"outputs/\" + date_str + \"/\" + prefix + \"clean_entity_type_map.yaml\"\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "# Sort the inner dictionary keys for each dataset URL\n",
    "sorted_data = {\n",
    "    url: dict(sorted(fields.items()))\n",
    "    for url, fields in clean_url_map.items()\n",
    "}\n",
    "\n",
    "# Save to YAML\n",
    "with open(output_file_path, \"w\") as file:\n",
    "    yaml.dump(sorted_data, file, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e16edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_str = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "output_file_path = \"outputs/\" + date_str + \"/\" + prefix + \"initial_entity_type_map.yaml\"\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "# Sort the inner dictionary keys for each dataset URL\n",
    "sorted_data = {\n",
    "    url: dict(sorted(fields.items()))\n",
    "    for url, fields in initial_url_map.items()\n",
    "}\n",
    "\n",
    "# Save to YAML\n",
    "with open(output_file_path, \"w\") as file:\n",
    "    yaml.dump(sorted_data, file, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Path to your YAML file\n",
    "input_file_path = \"outputs/2025-06-04/cedar_gemini_clean_entity_type_map.yaml\"\n",
    "\n",
    "# Load the YAML content\n",
    "with open(input_file_path, \"r\") as file:\n",
    "    loaded_data = yaml.safe_load(file)\n",
    "\n",
    "# Now `loaded_data` is a Python dictionary\n",
    "print(loaded_data.keys())  # For example, show the top-level URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7941bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e05890",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11beba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
